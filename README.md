NeuroLingo - Inclusive Education
NeuroLingo is an innovative sign language recognition system that leverages machine learning to bridge communication gaps for the hearing impaired community. This project uses MediaPipe for hand tracking and TensorFlow for gesture classification to translate sign language gestures into text in real-time.

Features:
Real-time Sign Language Recognition: Detects and interprets sign language gestures using a webcam
Multiple Gesture Support: Currently recognizes 'hello', 'thanks', and 'I love you' gestures
Educational Interface: Clean, intuitive UI designed for learning and practice
Two Recognition Modes:
Machine Learning Model (LSTM-based) for accurate recognition
Rule-based Fallback for when the model is unavailable
Visual Feedback: Displays hand landmarks and confidence scores

Technology Stack
Frontend: HTML5, CSS3, JavaScript
Machine Learning: TensorFlow, Keras
Computer Vision: MediaPipe Hands, OpenCV
Model Architecture: LSTM neural network
Development: Python
